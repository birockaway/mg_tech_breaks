{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Artificial Neural Networks](https://en.wikipedia.org/wiki/Artificial_neural_network)\n",
    "\n",
    "### What is it?\n",
    "It is a non-parametric classification / regression model which mimics biological neural networks architecture.\n",
    "\n",
    "### When do I use it?\n",
    "I want to predict / classify a response variable based on arbitrary data. Be it countinous (regression problem) or categorical (classification problem) response. NN model is especialy suitable when I want to classify N-dimensional objects like images. When I do Natural Language Processing.\n",
    "\n",
    "### Why should I use it?\n",
    "It can discover and incorporate implicit attributes like edgeness, curvature in images / sentiment, familyness in text.\n",
    "\n",
    "### Why should I NOT use it?\n",
    "Training lots of parameters and hyperparameters including number of layers and number of Neurons in each layer can be computationaly expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does it work?\n",
    "\n",
    "* Neural Network is a set of real valued nodes (Neurons), conected to each other forming layers.\n",
    "\n",
    "\n",
    "* First layer is input vector $X$, last one is output $y$. Other layers of Neurons are called hidden layers.\n",
    "\n",
    "\n",
    "* Value of j-th Neuron $a_j^{(L)}$ in L-th layer is computed by $a_j^{(L)} = \\sigma (\\sum_i a_i^{(L-1)}*w_{ij}^{(L-1)} + b_j$)\n",
    "\n",
    "\n",
    "* $\\sigma$ is called an activation function. Often it is a sigmoid like $\\sigma_1(t) = \\frac{1}{1+\\exp(-t)}$ or a ReLU function $\\sigma_2(t) = min(0, t)$.\n",
    "\n",
    "\n",
    "* Classcal design of NN where each Neuron in L-th layer is connected to all Neurons in (L+1)-th layer is called Multi Layer Perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Neuron img\n",
    "<img src=\"neuron_example.png\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron img\n",
    "<img src=\"nn_example.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How is it trained?\n",
    "\n",
    "In order to train the model, you need to fit quite a lot of parameters - all the weights and biases. **For fitting them we use gradient descent method called back propagation**.\n",
    "\n",
    "### Back propagation \n",
    "\n",
    "* First we define our Loss function $L$. It could be for example mean squared error $L = \\sum (a_j - y_j)^2$ or a Cross-Entropy.\n",
    "\n",
    "\n",
    "* The negative gradient of L is then computed by chain rule. \n",
    "\n",
    "\n",
    "* We define $z^{(L)} = w^{(L)}a^{(L-1)}+b^{(L)}$ and $a^{(L)} = \\sigma (z^{(L)})$.\n",
    "\n",
    "\n",
    "* For computing the influence of weight $w_{jk}^{(L)}$, connecting neuron $a_j^{(L-1)}$ to a output neuron $a_k^{(L)}$ we get $\\frac{\\partial L}{\\partial w_{jk}^{(L)}} = \\frac{\\partial L}{\\partial a_{j}^{(L)}} \\frac{\\partial a_{j}^{(L)}}{\\partial z_{j}^{(L)}} \\frac{\\partial z_{j}^{(L)}}{\\partial w_{jk}^{(L)}}$.\n",
    "\n",
    "\n",
    "* This partial derivative we compute for all the $w$ and $b$ and thus we optain a gradient $\\nabla$ for single given training row.\n",
    "\n",
    "\n",
    "* We do this for a small batch of N training datapoints -> make the avarage $\\bar{\\nabla} = \\frac{1}{N}\\sum\\nabla_i$ -> set the new weights as $W_{new} = W_{old} + \\eta \\bar{\\nabla}$, where $\\eta$ is a learning speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset - MNIST handwritten digits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"mnist_network.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST the dataset from web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from https://www.openml.org/d/554\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "X = X / 255.\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the MLP classifier to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.33761426\n",
      "Iteration 2, loss = 0.15967946\n",
      "Iteration 3, loss = 0.11584609\n",
      "Iteration 4, loss = 0.09466358\n",
      "Iteration 5, loss = 0.07962885\n",
      "Iteration 6, loss = 0.06791872\n",
      "Iteration 7, loss = 0.05955260\n",
      "Iteration 8, loss = 0.05253346\n",
      "Iteration 9, loss = 0.04665493\n",
      "Iteration 10, loss = 0.04187059\n",
      "Iteration 11, loss = 0.03726223\n",
      "Iteration 12, loss = 0.03377286\n",
      "Iteration 13, loss = 0.02985019\n",
      "Training loss did not improve more than tol=0.050000 for 10 consecutive epochs. Stopping.\n",
      "Training set score: 0.9935428571428572\n",
      "Test set score: 0.9689714285714286\n"
     ]
    }
   ],
   "source": [
    "# FIT THE MultiLayerPerceptron\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=20, alpha=1e-4,\n",
    "                    solver='sgd', verbose=10, tol=5e-2, random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "\n",
    "# train the model\n",
    "mlp.fit(train_X, train_y)\n",
    "print(f\"Training set score: {mlp.score(train_X, train_y)}\")\n",
    "print(f\"Test set score: {mlp.score(val_X, val_y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function for own images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_img_to_predictors(img_path):\n",
    "    img = Image.open(img_path)\n",
    "    # resize the original img to 28x28 pixel img\n",
    "    img = img.resize((28, 28))\n",
    "    img_arr = np.array(img)\n",
    "    # create a single-channel array\n",
    "    img_arr = np.mean(img_arr, 2)\n",
    "    %matplotlib inline\n",
    "    imshow(1 - img_arr/255)\n",
    "    #flatten the 2-D array to a vector\n",
    "    img_arr = img_arr.flatten()\n",
    "    # normalize the array to [0, 1] interval and invert\n",
    "    img_arr = (1 - img_arr / 255)\n",
    "\n",
    "    return img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1'], dtype='<U1')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let the model fit own images\n",
    "img_path = \"./data/num_2.png\"\n",
    "X_own = my_img_to_predictors(img_path)\n",
    "mlp.predict([X_own])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "[Scikit documentation](https://scikit-learn.org/stable/modules/neural_networks_supervised.html)\n",
    "\n",
    "[Wiki](https://en.wikipedia.org/wiki/Artificial_neural_network)\n",
    "\n",
    "[Cool video on backpropagation](https://www.youtube.com/watch?v=tIeHLnjs5U8&t=303s)\n",
    "\n",
    "[Article - adventuresinmachinelearning.com](https://adventuresinmachinelearning.com/neural-networks-tutorial/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
